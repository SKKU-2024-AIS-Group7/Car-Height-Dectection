{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 모듈 import\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "model_path = os.path.join(project_root, 'model')\n",
    "if model_path not in sys.path:\n",
    "    sys.path.append(model_path)\n",
    "\n",
    "weight_path = os.path.join(project_root, 'weight')\n",
    "if weight_path not in sys.path:\n",
    "    sys.path.append(weight_path)\n",
    "\n",
    "from model.height_detection_model import HeightPredictionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GPU 사용 가능여부 확인\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "hf_path = 'https://huggingface.co/jspark2000/yolov5-vehicle/resolve/main/best.pt'\n",
    "yolov5_model = torch.hub.load('ultralytics/yolov5', 'custom', path=hf_path, force_reload=True).to(device)\n",
    "\n",
    "mask_rcnn_model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(pretrained=True).to(device)\n",
    "mask_rcnn_model.eval()\n",
    "\n",
    "regression_model = HeightPredictionModel()\n",
    "regression_model.load_state_dict(torch.load('../weight/height_prediction_model.pth'))\n",
    "regression_model.to(device)\n",
    "regression_model.eval()\n",
    "\n",
    "scaler = joblib.load('../weight/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_square(image):\n",
    "    width, height = image.size\n",
    "    max_side = max(width, height)\n",
    "    padding = (\n",
    "        (max_side - width) // 2,\n",
    "        (max_side - height) // 2,\n",
    "        (max_side - width + 1) // 2,\n",
    "        (max_side - height + 1) // 2,\n",
    "    )\n",
    "    return torchvision.transforms.functional.pad(image, padding, fill=0, padding_mode='constant')\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file not found at {image_path}\")\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image_rgb\n",
    "\n",
    "\n",
    "def detect_objects(image, confidence_threshold=0.5):\n",
    "    results = yolov5_model(image)\n",
    "    boxes = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "    filtered_boxes = [box for box in boxes if box[4] >= confidence_threshold]\n",
    "    return filtered_boxes\n",
    "\n",
    "\n",
    "def segment_objects(image, boxes, target_size=(512, 512)):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Lambda(pad_to_square),\n",
    "        torchvision.transforms.Resize(target_size, interpolation=torchvision.transforms.InterpolationMode.BILINEAR),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    masks = []\n",
    "    all_outputs = []\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box[:4])\n",
    "        cropped_image = image_tensor[:, y1:y2, x1:x2]\n",
    "        resized_image = transform(cropped_image.permute(1, 2, 0).cpu().numpy()).to(device)\n",
    "        resized_image = resized_image.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = mask_rcnn_model(resized_image)\n",
    "            all_outputs.append(output)\n",
    "\n",
    "        max_height = 0\n",
    "        max_width = 0\n",
    "        best_mask = None\n",
    "\n",
    "        for i, mask in enumerate(output[0]['masks']):\n",
    "            mask_np = mask[0].mul(255).byte().cpu().numpy()\n",
    "            mask_resized = cv2.resize(mask_np, (x2 - x1, y2 - y1), interpolation=cv2.INTER_NEAREST)\n",
    "            mask_full_image = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "            mask_full_image[y1:y2, x1:x2] = mask_resized\n",
    "            height = calculate_height_from_mask(mask_np)\n",
    "            width = calculate_width_from_mask(mask_np)\n",
    "\n",
    "            if height > max_height and output[0]['labels'][i] == 3:\n",
    "                max_height = height\n",
    "                max_width = width\n",
    "                best_mask = mask_full_image\n",
    "\n",
    "        if max_height != 0:\n",
    "            angle = math.radians(15)\n",
    "            sin_angle = np.sin(angle)\n",
    "            cos_angle = np.cos(angle)\n",
    "\n",
    "            input_features = np.array([[max_height, max_height / max_width, sin_angle, cos_angle]])\n",
    "            input_features = scaler.transform(input_features)\n",
    "            input_tensor = torch.tensor(input_features, dtype=torch.float32).to(device)\n",
    "            real_height = regression_model(input_tensor).item()\n",
    "\n",
    "            masks.append((x1, y1, x2, y2, best_mask, real_height, max_height, max_width))\n",
    "\n",
    "    return masks, all_outputs\n",
    "\n",
    "\n",
    "def calculate_height_from_mask(mask):\n",
    "    max_height = 0\n",
    "\n",
    "    for col in range(mask.shape[1]):\n",
    "        y_indices = np.where(mask[:, col] > 127)[0]\n",
    "        if len(y_indices) > 0:\n",
    "            height = np.max(y_indices) - np.min(y_indices)\n",
    "            if height > max_height:\n",
    "                max_height = height\n",
    "    return max_height\n",
    "\n",
    "\n",
    "def calculate_width_from_mask(mask):\n",
    "    max_width = 0\n",
    "\n",
    "    for row in range(mask.shape[0]):\n",
    "        x_indices = np.where(mask[row, :] > 127)[0]\n",
    "        if len(x_indices) > 0:\n",
    "            width = np.max(x_indices) - np.min(x_indices)\n",
    "            if width > max_width:\n",
    "                max_width = width\n",
    "    return max_width\n",
    "\n",
    "\n",
    "def draw_boxes_and_masks(image, masks, outputs):\n",
    "    heights = []\n",
    "    widths = []\n",
    "\n",
    "    for _, mask_info in enumerate(masks):\n",
    "        x1, y1, x2, y2, mask, real_height, height, width = mask_info\n",
    "        heights.append(real_height)\n",
    "        widths.append(width)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'{real_height:.2f} mm', (x1, y1 - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask_color = np.zeros_like(image)\n",
    "            mask_color[:, :, 1] = mask\n",
    "            image = cv2.addWeighted(image, 1.0, mask_color, 0.5, 0)\n",
    "\n",
    "    return image, heights, widths\n",
    "\n",
    "\n",
    "def display_image_with_mask(resized_image, mask, height, label):\n",
    "    resized_image_np = resized_image.squeeze(0).permute(1, 2, 0).numpy()\n",
    "    resized_image_np = (resized_image_np * 255).astype(np.uint8)\n",
    "    \n",
    "    mask_image = np.zeros_like(resized_image_np)\n",
    "    mask_image[:, :, 1] = mask\n",
    "    \n",
    "    combined_image = cv2.addWeighted(resized_image_np, 1.0, mask_image, 0.5, 0)\n",
    "    \n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(combined_image)\n",
    "    plt.title(f'Resized Image with Mask, Height: {height}, Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main(image_path):    \n",
    "    image_rgb = load_image(image_path)\n",
    "    boxes = detect_objects(image_rgb)\n",
    "    vehicle_boxes = [box for box in boxes if int(box[5]) in [1, 10]]\n",
    "    masks, outputs = segment_objects(image_rgb, vehicle_boxes)\n",
    "    image_with_masks, heights, widths = draw_boxes_and_masks(image_rgb, masks, outputs)\n",
    "\n",
    "    output_image = cv2.cvtColor(image_with_masks, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite('../images/results/output_image_with_masks.jpg', output_image)\n",
    "    # return heights, widths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"../images/sample.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
